{"dataset_name":"dataset_conflicts_1-1_wildcard_preds_subsample-2000_recreated","pattern_eval_config_id":"conflicts_2-2_preds_semsim-fix-lemma_wildcard","num_samples":2000,"num_positive":599,"num_negative":1401,"semsim_configs":null,"ref_words":["accuse","arrest","clash","condemn","kill","slam","warn"],"ref_edges":null,"symbolic_eval_score":null,"semsim_eval_scores":{"0.0":{"precision":0.31169626454378446,"recall":0.8497495826377296,"f1":0.45609318996415765},"0.05":{"precision":0.2983425414364641,"recall":0.991652754590985,"f1":0.45868725868725874},"0.1":{"precision":0.2995438418651799,"recall":0.986644407345576,"f1":0.4595645412130637},"0.15":{"precision":0.30071077091306725,"recall":0.9181969949916527,"f1":0.4530477759472817},"0.2":{"precision":0.31169626454378446,"recall":0.8497495826377296,"f1":0.45609318996415765},"0.25":{"precision":0.35800344234079173,"recall":0.6944908180300501,"f1":0.4724588302101079},"0.3":{"precision":0.42650602409638555,"recall":0.5909849749582637,"f1":0.49545136459062283},"0.35":{"precision":0.47665056360708535,"recall":0.4941569282136895,"f1":0.4852459016393443},"0.4":{"precision":0.5314401622718052,"recall":0.4373956594323873,"f1":0.47985347985347976},"0.45":{"precision":0.5467289719626168,"recall":0.39065108514190316,"f1":0.45569620253164556},"0.5":{"precision":0.615916955017301,"recall":0.29716193656093487,"f1":0.4009009009009008},"0.55":{"precision":0.6911764705882353,"recall":0.2353923205342237,"f1":0.3511830635118307},"0.6":{"precision":0.7135135135135136,"recall":0.22036727879799667,"f1":0.33673469387755106},"0.65":{"precision":0.7094972067039106,"recall":0.21202003338898165,"f1":0.3264781491002571},"0.7":{"precision":0.7094972067039106,"recall":0.21202003338898165,"f1":0.3264781491002571},"0.75":{"precision":0.7094972067039106,"recall":0.21202003338898165,"f1":0.3264781491002571},"0.8":{"precision":0.7094972067039106,"recall":0.21202003338898165,"f1":0.3264781491002571},"0.85":{"precision":0.7062146892655368,"recall":0.20868113522537562,"f1":0.3221649484536082},"0.9":{"precision":0.7062146892655368,"recall":0.20868113522537562,"f1":0.3221649484536082},"0.95":{"precision":0.7062146892655368,"recall":0.20868113522537562,"f1":0.3221649484536082},"1.0":{"precision":0.6867469879518072,"recall":0.19031719532554256,"f1":0.2980392156862745}}}